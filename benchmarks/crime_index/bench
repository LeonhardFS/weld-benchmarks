#!/usr/bin/env python

import argparse
import pandas as pd
import grizzly.grizzly as gr
import numpy as np
import grizzly.numpy_weld as npw
import time

def crime_index_pandas(requests):
    # Get all city information with total population greater than 500,000
    data_big_cities = data[data["Total population"] > 500000]
    data_big_cities_new_df = data_big_cities[["State short"]]

    # Compute "crime index" proportional to
    # exp((Total population + 2*(Total adult population) - 2000*(Number of
    # robberies)) / 100000)
    data_big_cities_stats = data_big_cities[
        ["Total population", "Total adult population", "Number of robberies"]].values
    predictions = np.exp(np.dot(data_big_cities_stats,
                                np.array([1.0, 2.0, -2000.0])) / 100000.0)
    predictions = predictions / predictions.sum()
    data_big_cities_new_df["Crime index"] = predictions

    # Aggregate "crime index" scores by state
    data_big_cities_grouped_df = data_big_cities_new_df.groupby(
        "State short").sum()
    return data_big_cities_grouped_df["Crime index"]

def crime_index_grizzly(requests):
    # Get all city information with total population greater than 500,000
    data_big_cities = data[data["Total population"] > 500000]
    data_big_cities_new_df = data_big_cities[["State short"]]

    # Compute "crime index" proportional to
    # exp((Total population + 2*(Total adult population) - 2000*(Number of
    # robberies)) / 100000)
    data_big_cities_stats = data_big_cities[
        ["Total population", "Total adult population", "Number of robberies"]].values
    predictions = npw.exp(npw.dot(data_big_cities_stats, np.array(
        [1, 2, -2000], dtype=np.int64)) / 100000.0)
    predictions = predictions / predictions.sum()
    data_big_cities_new_df["Crime index"] = predictions

    # Aggregate "crime index" scores by state
    data_big_cities_grouped_df = data_big_cities_new_df.groupby(
        "State short").sum()
    return data_big_cities_grouped_df.evaluate(verbose=False).to_pandas()["Crime index"]


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="Run the Black Scholes benchmark"
    )
    parser.add_argument('-f', "--input_file_template", type=str, required=True,
                        help="Input file to use")
    parser.add_argument('-s', "--scale_factor", type=int, required=True,
                        help="Scale factor")

    cmdline_args = parser.parse_args()
    opt_dict = vars(cmdline_args)
    input_file_template = opt_dict["input_file_template"]
    input_file = input_file_template % opt_dict["scale_factor"]

    data = pd.read_csv(input_file, delimiter='|')
    data.dropna(inplace=True)
    start = time.time()
    result = crime_index_pandas(data)
    end = time.time()
    result = sum(sorted(result, reverse=True)[:3])
    print "Pandas: %.4f (result=%.4f)" % (end - start, result)

    data = pd.read_csv(input_file, delimiter='|')
    data.dropna(inplace=True)
    data = gr.DataFrameWeld(data)
    start = time.time()
    result = crime_index_grizzly(data)
    end = time.time()
    result = sum(sorted(result, reverse=True)[:3])
    print "Grizzly: %.4f (result=%.4f)" % (end - start, result)
